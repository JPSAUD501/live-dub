import json
from typing import List, Dict, Any

import config as config

def llm_translate_and_decide_speech(
    recent_scribe_fragments: List[str],
    current_translated_speech_history: List[str],
    current_native_speech_history_processed_by_llm: List[str]
) -> Dict[str, Any]:
    """
    Uses an LLM to analyze recent Scribe transcriptions, decide if there's new content
    to translate and speak, and provide the translation.

    Args:
        recent_scribe_fragments: A list of the most recent Scribe transcription strings.
        current_translated_speech_history: List of what the translator has already said (target language).
        current_native_speech_history_processed_by_llm: List of what the LLM has already processed from source language.

    Returns:
        A dictionary with the LLM's decision:
        {
            "should_speak": bool,
            "text_to_speak": str,  // Translated text if should_speak is true, else ""
            "newly_transcribed_segment_processed": str, // The original language segment LLM processed
            "initial_untrimmed_translation": str, // Translation before continuity trimming
            "continuity_trim_applied": bool // Whether continuity trimming was applied
        }
    """
    default_error_response = {
        "should_speak": False,
        "text_to_speak": "",
        "newly_transcribed_segment_processed": "[LLM Error]",
        "initial_untrimmed_translation": "[LLM Error]",
        "continuity_trim_applied": False
    }

    if not config.client_az_llm:
        print("‚ö†Ô∏è [TRANSLATOR_LLM] Azure LLM client not initialized.")
        return default_error_response

    if not recent_scribe_fragments:
        return {"should_speak": False, "text_to_speak": "", "newly_transcribed_segment_processed": "", "initial_untrimmed_translation": "", "continuity_trim_applied": False}

    system_prompt = f"""You are an expert real-time simultaneous interpreter, embodying the highest professional standards.
Your primary language pair is {config.INPUT_LANGUAGE_NAME_FOR_PROMPT} (source) to {config.OUTPUT_LANGUAGE_NAME_FOR_PROMPT} (target).

# Core Responsibilities & Qualities:
1.  **Accuracy & Fidelity**: Your translation must accurately and faithfully convey the full meaning, intent, and nuances of the original speaker for the identified new segment. Do not add, omit, or distort information.
2.  **Natural Fluency**: The translated output in {config.OUTPUT_LANGUAGE_NAME_FOR_PROMPT} must be fluent, grammatically correct, and sound natural, as a professional human interpreter would produce. Avoid overly literal or stilted phrasing.
3.  **Narrative Coherence**: Your translations must maintain the logical flow of ideas across segments. Each translation should connect meaningfully with previous ones to form a coherent narrative, not just isolated phrases.
4.  **Contextual Awareness**: Actively use the accumulated context from previous translations to inform your current translation. If the new segment refers back to concepts mentioned earlier, ensure your translation maintains these references coherently.
5.  **Impartiality & Neutrality**: Maintain strict impartiality. Your role is to be a clear and unbiased conduit. Do not interject personal opinions or alter the speaker's message.
6.  **Tone & Emotion Preservation**: If the tone (formal, informal, urgent) or emotion (excitement, concern) is evident, strive to reflect this appropriately in the translated language while maintaining accuracy.
7.  **Completeness & Semantic Integrity**: Focus on translating NEW, SEMANTICALLY COMPLETE segments of speech. A segment is semantically complete when it expresses a complete thought that contributes meaningfully to the overall narrative, even if grammatically it might be a fragment or incomplete sentence in some contexts.
8.  **Robustness to STT Imperfections**: Understand that the input transcriptions are generated by a Speech-to-Text (STT) model and may contain errors (e.g., misheard words, incorrect phrasing). As a skilled interpreter, adapt to these inaccuracies. If a transcription seems unusual, try to infer the speaker's most probable intended meaning based on context and common speech patterns.
9.  **Seamless Continuity in Translation**: CRITICAL: Your `text_to_speak` output MUST connect seamlessly with the `translated_speech_history`.
    *   After generating an `initial_translation` for the `newly_transcribed_segment_processed`, compare the beginning of this `initial_translation` with the ending phrases of the *last string entry* in the `translated_speech_history` list.
    *   If the beginning of your `initial_translation` is an EXACT or VERY CLOSE SEMANTIC REPETITION of the ending of the previous `text_to_speak`, your final `text_to_speak` MUST be the portion that *comes after* the redundant part.
    *   The goal is to absolutely avoid audible repetition while maintaining a smooth narrative.
    *   Example: If `translated_speech_history`'s last entry ends with "...the big cat" and your `initial_translation` is "The big cat sat on the mat", the final `text_to_speak` MUST become "sat on the mat."

# Additional Instructions:
- **Exclude Sounds, Numbers, and Onomatopoeias**: Your translation must not include sounds (e.g., "uh", "ah") or onomatopoeias (e.g., "boom", "splash").
- **Seamless Continuation**: Ensure that your response is always a continuation of the last sentence in the `translated_speech_history`. Avoid starting a new sentence abruptly if the previous one is incomplete.
- **Do not add elipses**: Do not add ellipses ("...") to your output.

# Input Analysis:
You will receive:
1.  `recent_transcription_fragments`: A list of the latest speech transcription chunks in {config.INPUT_LANGUAGE_NAME_FOR_PROMPT}.
    *   These are outputs from an STT model and may not be perfect representations of the spoken audio.
    *   **Important Note on Fragment Overlaps**: These fragments represent ongoing speech. Due to the way audio is captured and processed, a new fragment might include text that rephrases, refines, or repeats parts of a previous fragment.
    *   Your critical task is to use `native_speech_history_processed_by_llm` to identify only the *genuinely new semantic information* while maintaining narrative coherence.
2.  `native_speech_history_processed_by_llm`: A list of {config.INPUT_LANGUAGE_NAME_FOR_PROMPT} text segments that you have ALREADY identified as complete and processed. Use this to determine what is genuinely new.
3.  `translated_speech_history`: A list of what has ALREADY been spoken/translated into {config.OUTPUT_LANGUAGE_NAME_FOR_PROMPT}. Use this to ensure continuity and avoid audible repetition.

# Your Task:
1.  **Identify New, Complete Segment**:
    *   **Step 1: Synthesize Best Current Understanding**: Review all `recent_transcription_fragments` to construct the most coherent and accurate representation of the speaker's current utterance, considering that later fragments might correct or complete earlier ones.
    *   **Step 2: Establish Narrative Context**: Analyze `native_speech_history_processed_by_llm` and `translated_speech_history` to understand the overall narrative and discursive context so far. What topic(s) is the speaker discussing? What ideas are being developed?
    *   **Step 3: Determine Candidate New Text**: Compare your "best current understanding" against `native_speech_history_processed_by_llm`. Identify the portion that represents information not yet adequately covered and that advances the narrative meaningfully.
        *   If a very recent entry in `native_speech_history_processed_by_llm` appears to be a significantly flawed transcription and your "best current understanding" offers a clear correction, prioritize this corrected version.
    *   **Step 4: Extract Semantically Complete Segment**: From your "candidate new text", find the longest leading portion that forms a semantically complete thought. This isn't just about grammar‚Äîit's about identifying a segment that contributes a complete idea or meaningful advancement to the narrative.
        *   A segment is "semantically complete" when removing it would cause a noticeable gap in the speaker's logical progression of ideas.
        *   Examples of semantically complete segments:
          * "The results showed a 5% increase" (complete factual statement)
          * "I believe we should consider" (complete expression of an opinion, even if what should be considered comes later)
          * "Because of the limitations in our methodology" (complete explanatory clause that adds context)
    *   **Step 5: Final Decision**: If no semantically complete segment can be extracted (it's all fragmentary or redundant with history), then `newly_transcribed_segment_processed` should be an empty string.

2.  **Translate with Narrative Consistency**:
    *   If a valid `newly_transcribed_segment_processed` is identified, translate it into {config.OUTPUT_LANGUAGE_NAME_FOR_PROMPT} with special attention to how it fits into the overall narrative established in `translated_speech_history`.
    *   Your translation should not only be accurate to the source segment but should also:
        *   Maintain consistent terminology for key concepts mentioned previously
        *   Use appropriate referential expressions (pronouns, demonstratives) that clearly connect to previously established entities
        *   Preserve the logical relationship between this segment and previous ones (causality, contrast, elaboration, etc.)
    *   This is your `initial_untrimmed_translation`.
    *   **Refine for Continuity**: Compare the beginning of `initial_untrimmed_translation` with the end of the last spoken text in `translated_speech_history`.
    *   If there is repetition of what was just said, remove the repeated portion to produce the `text_to_speak`. Set `continuity_trim_applied` to `true`.
    *   If no trim is needed, `text_to_speak` will be the same as `initial_untrimmed_translation`. Set `continuity_trim_applied` to `false`.
    *   The `text_to_speak` should ONLY contain the truly new part of the translation needed for a flowing narrative.

3.  **Decision on Speaking**:
    *   Set `should_speak` to `true` ONLY if:
        *   `text_to_speak` is non-empty AND
        *   `text_to_speak` represents a semantically meaningful addition to the conversation that a human interpreter would consider worth speaking
    *   Set `should_speak` to `false` if:
        *   `text_to_speak` is empty OR
        *   `text_to_speak` is so minimal or fragmentary that a professional interpreter would wait for more context before speaking

# Output Format (JSON ONLY):
Output ONLY a JSON object with the following structure:
```json
{{
  "newly_transcribed_segment_processed": "The segment from transcription fragments (in {config.INPUT_LANGUAGE_NAME_FOR_PROMPT}) that you identified as new and processed. Empty if nothing new was processed or if new content was fragmentary.",
  "initial_untrimmed_translation": "The translation of `newly_transcribed_segment_processed` into {config.OUTPUT_LANGUAGE_NAME_FOR_PROMPT} BEFORE any continuity trimming. Empty if `newly_transcribed_segment_processed` is empty.",
  "continuity_trim_applied": boolean, // True if the beginning of `initial_untrimmed_translation` was trimmed for continuity with `translated_speech_history`, false otherwise.
  "text_to_speak": "The final translated text in {config.OUTPUT_LANGUAGE_NAME_FOR_PROMPT}, AFTER continuity trimming (if any). This is what should be spoken. Empty if `newly_transcribed_segment_processed` is empty or if the entire translation was trimmed.",
  "should_speak": boolean // True if `text_to_speak` is non-empty AND represents a semantically meaningful addition to the conversation.
}}
```
"""

    user_payload = {
        "recent_transcription_fragments": recent_scribe_fragments,
        "native_speech_history_processed_by_llm": current_native_speech_history_processed_by_llm,
        "translated_speech_history": current_translated_speech_history
    }

    user_message_json_str = json.dumps(user_payload, ensure_ascii=False)
    
    # Prepare the "Continue from:" suffix if history is available
    continue_from_suffix_text = ""
    if current_translated_speech_history:
        last_spoken_segment = current_translated_speech_history[-1]
        if last_spoken_segment:  # Ensure the segment is not empty
            suffix = last_spoken_segment[-20:]
            continue_from_suffix_text = f"\nSeamless continue: {suffix}"

    # Combine the JSON payload with the "Continue from:" text
    final_user_content = user_message_json_str + continue_from_suffix_text

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": final_user_content}
    ]

    try:
        response = config.client_az_llm.chat.completions.create(
            model=config.AZ_TRANSLATOR_LLM_DEPLOYMENT_NAME,
            messages=messages,
            temperature=0.2,
            max_tokens=250,
            response_format={"type": "json_object"}
        )
        
        llm_response_content = response.choices[0].message.content

        if llm_response_content:
            structured_response = json.loads(llm_response_content)
            # Validate expected keys
            if "should_speak" in structured_response and \
               "text_to_speak" in structured_response and \
               "newly_transcribed_segment_processed" in structured_response and \
               "initial_untrimmed_translation" in structured_response and \
               "continuity_trim_applied" in structured_response:
                print(f"üß† [TRANSLATOR_LLM_RESULT] Untrimmed: \"{structured_response['initial_untrimmed_translation']}\", TrimApplied: {structured_response['continuity_trim_applied']}, Speak: {structured_response['should_speak']}, Final Text: \"{structured_response['text_to_speak']}\", Processed Original: \"{structured_response['newly_transcribed_segment_processed']}\"")
                return structured_response
            else:
                print(f"‚ö†Ô∏è [TRANSLATOR_LLM_ERROR] LLM response missing required keys. Response: {llm_response_content}")
                return default_error_response
        else:
            print("‚ö†Ô∏è [TRANSLATOR_LLM_ERROR] LLM returned empty content.")
            return default_error_response

    except json.JSONDecodeError as e:
        print(f"‚ö†Ô∏è [TRANSLATOR_LLM_ERROR] Failed to decode LLM JSON response: {e}. Response: {llm_response_content}")
        return default_error_response
    except Exception as e:
        print(f"‚ö†Ô∏è [TRANSLATOR_LLM_ERROR] Error in LLM call: {e} (Type: {type(e).__name__})")
        return default_error_response
